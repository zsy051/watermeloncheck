<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>麦克风音频检测</title>
<style>
  body { font-family: Arial, sans-serif; text-align: center; margin: 20px; }
  canvas { border: 1px solid #ccc; display: block; margin: 20px auto; width: 90%; height: 200px; }
  #controls { margin-bottom: 20px; }
</style>
</head>
<body>
  <h2>麦克风音频检测</h2>
  <div id="controls">
    <button id="toggleBtn">开始检测</button>
    <label for="updateInterval">更新时间 (ms): </label>
    <input id="updateInterval" type="number" value="100" step="10" min="10" />
    <label for="threshold">分贝阈值 (dB): </label>
    <input id="threshold" type="number" value="-20" step="1" min="-50" max="0" />
  </div>
  <canvas id="graphCanvas"></canvas>
  <p id="status">状态: 未开始检测</p>

<script>
  const canvas = document.getElementById('graphCanvas');
  const ctx = canvas.getContext('2d');
  const toggleBtn = document.getElementById('toggleBtn');
  const updateIntervalInput = document.getElementById('updateInterval');
  const thresholdInput = document.getElementById('threshold');
  const status = document.getElementById('status');

  canvas.width = window.innerWidth * 0.9;
  canvas.height = 200;

  let audioContext, analyser, microphoneStream, animationFrame;
  let isDetecting = false;

  function drawGraph(dataArray, bufferLength) {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.beginPath();
    const sliceWidth = canvas.width / bufferLength;
    let x = 0;
    for (let i = 0; i < bufferLength; i++) {
      const v = dataArray[i] / 128.0;
      const y = v * canvas.height / 2;
      if (i === 0) {
        ctx.moveTo(x, y);
      } else {
        ctx.lineTo(x, y);
      }
      x += sliceWidth;
    }
    ctx.lineTo(canvas.width, canvas.height / 2);
    ctx.strokeStyle = 'green';
    ctx.lineWidth = 2;
    ctx.stroke();
  }

  async function startDetection() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioContext.createAnalyser();
      microphoneStream = audioContext.createMediaStreamSource(stream);
      microphoneStream.connect(analyser);
      analyser.fftSize = 2048;

      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);

      isDetecting = true;
      status.textContent = '状态: 检测中...';

      function loop() {
        if (!isDetecting) return;
        analyser.getByteTimeDomainData(dataArray);
        drawGraph(dataArray, bufferLength);
        animationFrame = requestAnimationFrame(loop);
      }

      loop();
    } catch (err) {
      status.textContent = `状态: 无法访问麦克风 (${err.message})`;
    }
  }

  function stopDetection() {
    isDetecting = false;
    cancelAnimationFrame(animationFrame);
    status.textContent = '状态: 检测已停止';
    if (microphoneStream) {
      microphoneStream.mediaStream.getTracks().forEach(track => track.stop());
    }
  }

  toggleBtn.addEventListener('click', () => {
    if (isDetecting) {
      stopDetection();
      toggleBtn.textContent = '开始检测';
    } else {
      startDetection();
      toggleBtn.textContent = '停止检测';
    }
  });
</script>
</body>
</html>